<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction on The Shubham Co</title>
    <link>http://localhost:1313/projects/core-systems/in-memory-cache/1_introduction/</link>
    <description>Recent content in Introduction on The Shubham Co</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/projects/core-systems/in-memory-cache/1_introduction/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>In-Memory Cache — Problem Statement</title>
      <link>http://localhost:1313/projects/core-systems/in-memory-cache/1_introduction/1_1_problem-statement/</link>
      <pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/core-systems/in-memory-cache/1_introduction/1_1_problem-statement/</guid>
      <description>&lt;h2 id=&#34;1-context&#34;&gt;1. Context&lt;/h2&gt;&#xA;&lt;p&gt;In many backend systems, the same pieces of data are requested repeatedly:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;user profiles&lt;/li&gt;&#xA;&lt;li&gt;permissions / entitlements&lt;/li&gt;&#xA;&lt;li&gt;reference data (currencies, countries, configs)&lt;/li&gt;&#xA;&lt;li&gt;product metadata&lt;/li&gt;&#xA;&lt;li&gt;frequently queried aggregates&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;If every request fetches this data from a database or remote service, latency and cost quickly become unacceptable.&lt;/p&gt;&#xA;&lt;p&gt;This project starts from a simple request:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;We need a fast, in-memory cache for frequently accessed data.&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;At this stage, we intentionally avoid jumping to specific eviction algorithms.&lt;br&gt;&#xA;First we define the problem clearly — like a real engineering task.&lt;/p&gt;</description>
    </item>
    <item>
      <title>In-Memory Cache — Why Eviction Is Needed</title>
      <link>http://localhost:1313/projects/core-systems/in-memory-cache/1_introduction/1_2_why-eviction-is-needed/</link>
      <pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/projects/core-systems/in-memory-cache/1_introduction/1_2_why-eviction-is-needed/</guid>
      <description>&lt;h2 id=&#34;1-the-core-constraint-memory-is-finite&#34;&gt;1. The Core Constraint: Memory Is Finite&lt;/h2&gt;&#xA;&lt;p&gt;A cache exists to store data in memory for fast access — but memory is not unlimited.&lt;/p&gt;&#xA;&lt;p&gt;If the cache grows without bounds:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;memory usage increases continuously&lt;/li&gt;&#xA;&lt;li&gt;latency becomes unstable (GC pressure in managed runtimes)&lt;/li&gt;&#xA;&lt;li&gt;the process risks out-of-memory failures&lt;/li&gt;&#xA;&lt;li&gt;overall system reliability degrades&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;So a production-grade cache must be &lt;strong&gt;bounded&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;A bounded cache implies a hard truth:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;When the cache is full, something must be removed.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
